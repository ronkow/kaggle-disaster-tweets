{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **LIBRARIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os           # os.path.join\n",
    "import csv          # csv.reader\n",
    "import numpy as np  # np.concatenate\n",
    "import re           # re.sub\n",
    "import pandas as pd  # pd.DataFrame \n",
    "\n",
    "#pd.get_dummies\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer, MultiLabelBinarizer  # fit_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ronkow/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "porter = PorterStemmer()\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **GLOBAL CONSTANTS, DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUNC = '''!?.,;:$&*^~_\"`(){}[]/\\|<>=%+-'''  # exclude # and @ and '\n",
    "\n",
    "STOP_WORDS = set(stopwords.words('english')) # returns a set of stop words\n",
    "ADD_WORDS = {\"i'm\"}\n",
    "STOP_WORDS = STOP_WORDS.union(ADD_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data/\"\n",
    "\n",
    "DATA_FILE_TEXT = os.path.join(DATA_DIR, \"train_text9.csv\")           # train_text9.csv is a SMALL DATASET used to test the code\n",
    "DATA_FILE_KEYWORD = os.path.join(DATA_DIR, \"train_keyword9.csv\")     # train_keyword9.csv is a SMALL DATASET used to test the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **THESE TWO FUNCTIONS WILL NOT BE USED**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_string(filepath):\n",
    "    with open(filepath) as f:\n",
    "        s = f.read()      \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_list_of_lists(filepath):\n",
    "    text_list = []\n",
    "    with open(filepath) as f:\n",
    "        for row in csv.reader(f):\n",
    "            text_list.append(row)\n",
    "    return text_list[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"text\"\n",
      "\"Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all\"\n",
      "\"Forest fire near La Ronge Sask. Canada\"\n",
      "\"All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected\"\n",
      "\"13,000 people receive #wildfires evacuation orders in California \"\n",
      "\"Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school\"\n",
      "\"#RockyFire Update => California Hwy. 20 closed in both directions due to Lake County fire - #CAfire #wildfires\"\n",
      "\"#flood #disaster Heavy rain causes flash flooding of streets in Manitou, Colorado Springs areas\"\n",
      "\"I'm on top of the hill and I can see a fire in the woods...\"\n",
      "\"There's an emergency evacuation happening now in the building across the street\"\n",
      "\n",
      "[['Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all'], ['Forest fire near La Ronge Sask. Canada'], [\"All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected\"], ['13,000 people receive #wildfires evacuation orders in California '], ['Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school'], ['#RockyFire Update => California Hwy. 20 closed in both directions due to Lake County fire - #CAfire #wildfires'], ['#flood #disaster Heavy rain causes flash flooding of streets in Manitou, Colorado Springs areas'], [\"I'm on top of the hill and I can see a fire in the woods...\"], [\"There's an emergency evacuation happening now in the building across the street\"]]\n"
     ]
    }
   ],
   "source": [
    "# CHECK\n",
    "s = file_to_string(DATA_FILE_TEXT)\n",
    "print(s)\n",
    "\n",
    "text_list1 = csv_to_list_of_lists(DATA_FILE_TEXT)\n",
    "print(text_list1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ONE HOT ENCODE TEXT** (USING SMALL DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_list(filepath):\n",
    "    token_list = []\n",
    "    with open(filepath) as f:\n",
    "        for row in csv.reader(f):\n",
    "            token_list.append(row[0])\n",
    "\n",
    "    token_list = token_list[1:]  # exclude column label\n",
    "    return token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE THIS IN FUNCTION list_of_token_lists()\n",
    "\n",
    "def csv_to_list_of_strings(filepath):\n",
    "    text_list = []\n",
    "    with open(filepath) as f:\n",
    "        for row in csv.reader(f):\n",
    "            text_list.append(row[0])\n",
    "    return text_list[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAME FUNCTION AS IN 1_select_bagofwords.ipynb\n",
    "\n",
    "def clean_doc_text(doc):\n",
    "    \"\"\"\n",
    "    ARGUMENT: text (string)\n",
    "    RETURN: list of tokens\n",
    "    \"\"\"\n",
    "    doc = doc.replace('...',' ... ')\n",
    "    doc = doc.replace(\"'\",' ')\n",
    "    for p in PUNC:\n",
    "        doc = doc.replace(p,'')\n",
    "  \n",
    "    tokens = doc.split()                                             # returns a list of tokens\n",
    "    tokens = [w.lower() for w in tokens]                             # convert all letters to lower case  \n",
    "    tokens = [w for w in tokens if not w in STOP_WORDS]              # exclude stop words\n",
    "    \n",
    "    tokens = [w for w in tokens if not w.isdigit()]\n",
    "\n",
    "    tokens = [porter.stem(w) for w in tokens]                        # stemming\n",
    "    tokens = [w for w in tokens if len(w)>=2]                        # include only words with length >= 2\n",
    "    \n",
    "    return tokens                                                    # list of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_doc_text_bow(tokens):\n",
    "    tokens = [w for w in tokens if w in token_list]                  # include only tokens in selected bag of words\n",
    "    return tokens                                                    # list of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_of_token_lists_text(text_list):\n",
    "    text_token_list = []\n",
    "    \n",
    "    for x in text_list:\n",
    "        y = clean_doc_text(x)\n",
    "        y = clean_doc_text_bow(y)\n",
    "        text_token_list.append(y)\n",
    "    return text_token_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **RUN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['us', 'fire', 'evacu', 'peopl', 'california', 'got', 'caus', 'flood', 'see', 'emerg', 'build', 'come', 'get', 'live', 'day', 'car', 'crash', 'look', 'new', 'polic']\n",
      "\n",
      "['Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all', 'Forest fire near La Ronge Sask. Canada', \"All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected\", '13,000 people receive #wildfires evacuation orders in California ', 'Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school', '#RockyFire Update => California Hwy. 20 closed in both directions due to Lake County fire - #CAfire #wildfires', '#flood #disaster Heavy rain causes flash flooding of streets in Manitou, Colorado Springs areas', \"I'm on top of the hill and I can see a fire in the woods...\", \"There's an emergency evacuation happening now in the building across the street\"]\n",
      "\n",
      "[['us'], ['fire'], ['evacu'], ['peopl', 'evacu', 'california'], ['got'], ['california', 'fire'], ['caus', 'flood'], ['see', 'fire'], ['emerg', 'evacu', 'build']]\n"
     ]
    }
   ],
   "source": [
    "token_list = csv_to_list('data/tokens/train_text_token100.csv')\n",
    "print(token_list[0:20])\n",
    "print('')\n",
    "\n",
    "text_list = csv_to_list_of_strings(DATA_FILE_TEXT)\n",
    "print(text_list)\n",
    "print('')\n",
    "\n",
    "text_token_list = list_of_token_lists_text(text_list)\n",
    "print(text_token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 1 0 0 1 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 1 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 1 0]\n",
      " [1 0 0 1 1 0 0 0 0 0 0]]\n",
      "(9, 11)\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "[['build' 'california' 'caus' 'emerg' 'evacu' 'fire' 'flood' 'got'\n",
      "  'peopl' 'see' 'us']]\n",
      "(1, 11)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "onehot_multi_text = MultiLabelBinarizer()\n",
    "\n",
    "onehot_text_nolabel = onehot_multi_text.fit_transform(text_token_list)\n",
    "num_row, num_col = onehot_text_nolabel.shape\n",
    "\n",
    "print(onehot_text_nolabel)\n",
    "print(onehot_text_nolabel.shape)\n",
    "print(type(onehot_text_nolabel))\n",
    "print('')\n",
    "\n",
    "text_labels = onehot_multi_text.classes_\n",
    "text_labels = text_labels.reshape(1, num_col)\n",
    "\n",
    "print(text_labels)\n",
    "print(text_labels.shape)\n",
    "print(type(text_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['build' 'california' 'caus' 'emerg' 'evacu' 'fire' 'flood' 'got'\n",
      "  'peopl' 'see' 'us']\n",
      " [0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 1 0 0 1 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 1 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 1 0]\n",
      " [1 0 0 1 1 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "onehot_text = np.concatenate((text_labels,onehot_text_nolabel), axis=0)\n",
    "print(onehot_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ONE HOT ENCODE KEYWORDS** (USING SMALL DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_doc_keyword(doc):\n",
    "    \"\"\"\n",
    "    ARGUMENT: text (string)\n",
    "    RETURN: list of tokens\n",
    "    \"\"\"\n",
    "    for p in PUNC:\n",
    "        doc = doc.replace(p,'')\n",
    "  \n",
    "    tokens = doc.split()                                 # returns a list of tokens\n",
    "    tokens = [w.lower() for w in tokens]                 # convert all characters to lower case  \n",
    "    tokens = [re.sub(r'\\d+', '_', w) for w in tokens]    # sub numbers with underscore\n",
    "    tokens = ['kw_'+ w for w in tokens]\n",
    "    return tokens                                        # list of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"keyword\"\n",
      "\"earthquake\"\n",
      "\"forestfire\"\n",
      "\"evacuation\"\n",
      "\"wildfires\"\n",
      "\"wildfires\"\n",
      "\"wildfires\"\n",
      "\"flood\"\n",
      "\"fire\"\n",
      "\"evacuation\"\n",
      "\n",
      "\n",
      "['kw_keyword', 'kw_earthquake', 'kw_forestfire', 'kw_evacuation', 'kw_wildfires', 'kw_wildfires', 'kw_wildfires', 'kw_flood', 'kw_fire', 'kw_evacuation']\n"
     ]
    }
   ],
   "source": [
    "# CHECK\n",
    "\n",
    "s = file_to_string(DATA_FILE_KEYWORD)\n",
    "print(s)\n",
    "print('')\n",
    "\n",
    "keyword_list1 = clean_doc_keyword(s)\n",
    "print(keyword_list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_of_token_lists_keyword(keyword_list):\n",
    "    keyword_token_list = []\n",
    "    \n",
    "    for x in keyword_list:\n",
    "        y = clean_doc_keyword(x)\n",
    "        keyword_token_list.append(y)\n",
    "    return keyword_token_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **RUN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['earthquake', 'forestfire', 'evacuation', 'wildfires', 'wildfires', 'wildfires', 'flood', 'fire', 'evacuation']\n",
      "\n",
      "[['kw_earthquake'], ['kw_forestfire'], ['kw_evacuation'], ['kw_wildfires'], ['kw_wildfires'], ['kw_wildfires'], ['kw_flood'], ['kw_fire'], ['kw_evacuation']]\n"
     ]
    }
   ],
   "source": [
    "keyword_list = csv_to_list_of_strings(DATA_FILE_KEYWORD)\n",
    "print(keyword_list)\n",
    "print('')\n",
    "\n",
    "keyword_token_list = list_of_token_lists_keyword(keyword_list)\n",
    "print(keyword_token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0 0 0]\n",
      " [0 0 0 0 1 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 0 1 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 1 0 0 0 0]]\n",
      "(9, 6)\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "[['kw_earthquake' 'kw_evacuation' 'kw_fire' 'kw_flood' 'kw_forestfire'\n",
      "  'kw_wildfires']]\n",
      "(1, 6)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "onehot_multi_keyword = MultiLabelBinarizer()\n",
    "onehot_keyword_nolabel = onehot_multi_keyword.fit_transform(keyword_token_list)\n",
    "num_row, num_col = onehot_keyword_nolabel.shape\n",
    "\n",
    "print(onehot_keyword_nolabel)\n",
    "print(onehot_keyword_nolabel.shape)\n",
    "print(type(onehot_keyword_nolabel))\n",
    "print('')\n",
    "\n",
    "keyword_labels = onehot_multi_keyword.classes_\n",
    "keyword_labels = keyword_labels.reshape(1, num_col)\n",
    "\n",
    "print(keyword_labels)\n",
    "print(keyword_labels.shape)\n",
    "print(type(keyword_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['kw_earthquake' 'kw_evacuation' 'kw_fire' 'kw_flood' 'kw_forestfire'\n",
      "  'kw_wildfires']\n",
      " [1 0 0 0 0 0]\n",
      " [0 0 0 0 1 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 0 1 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 1 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "onehot_keyword = np.concatenate((keyword_labels,onehot_keyword_nolabel), axis=0)\n",
    "print(onehot_keyword)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **CONCATENATE KEYWORD AND TEXT ONE HOT DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['kw_earthquake' 'kw_evacuation' 'kw_fire' 'kw_flood' 'kw_forestfire'\n",
      "  'kw_wildfires' 'build' 'california' 'caus' 'emerg' 'evacu' 'fire'\n",
      "  'flood' 'got' 'peopl' 'see' 'us']\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0]\n",
      " [0 1 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "onehot_train = np.concatenate((onehot_keyword,onehot_text), axis=1)\n",
    "print(onehot_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **CONVERT NUMPY ARRAY TO DATAFRAME**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kw_earthquake</th>\n",
       "      <th>kw_evacuation</th>\n",
       "      <th>kw_fire</th>\n",
       "      <th>kw_flood</th>\n",
       "      <th>kw_forestfire</th>\n",
       "      <th>kw_wildfires</th>\n",
       "      <th>build</th>\n",
       "      <th>california</th>\n",
       "      <th>caus</th>\n",
       "      <th>emerg</th>\n",
       "      <th>evacu</th>\n",
       "      <th>fire</th>\n",
       "      <th>flood</th>\n",
       "      <th>got</th>\n",
       "      <th>peopl</th>\n",
       "      <th>see</th>\n",
       "      <th>us</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  kw_earthquake kw_evacuation kw_fire kw_flood kw_forestfire kw_wildfires  \\\n",
       "0             1             0       0        0             0            0   \n",
       "1             0             0       0        0             1            0   \n",
       "2             0             1       0        0             0            0   \n",
       "3             0             0       0        0             0            1   \n",
       "4             0             0       0        0             0            1   \n",
       "5             0             0       0        0             0            1   \n",
       "6             0             0       0        1             0            0   \n",
       "7             0             0       1        0             0            0   \n",
       "8             0             1       0        0             0            0   \n",
       "\n",
       "  build california caus emerg evacu fire flood got peopl see us  \n",
       "0     0          0    0     0     0    0     0   0     0   0  1  \n",
       "1     0          0    0     0     0    1     0   0     0   0  0  \n",
       "2     0          0    0     0     1    0     0   0     0   0  0  \n",
       "3     0          1    0     0     1    0     0   0     1   0  0  \n",
       "4     0          0    0     0     0    0     0   1     0   0  0  \n",
       "5     0          1    0     0     0    1     0   0     0   0  0  \n",
       "6     0          0    1     0     0    0     1   0     0   0  0  \n",
       "7     0          0    0     0     0    1     0   0     0   1  0  \n",
       "8     1          0    0     1     1    0     0   0     0   0  0  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.DataFrame(data=onehot_train[1:], columns=onehot_train[0,0:])\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_csv(dataframe, filepath):\n",
    "    csvfile = dataframe.to_csv(filepath, encoding='utf-8', index=False)\n",
    "    \n",
    "def csv_to_dataframe(filepath):\n",
    "    df = pd.read_csv(filepath)\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE_BOW = os.path.join(DATA_DIR, \"bow/train_bow9.csv\")\n",
    "\n",
    "dataframe_to_csv(train_df, DATA_FILE_BOW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **NOW WE CREATE COMPLETE TRAINING DATASET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE_TEXT = os.path.join(DATA_DIR, \"train_text.csv\")           \n",
    "DATA_FILE_KEYWORD = os.path.join(DATA_DIR, \"train_keyword.csv\")\n",
    "DATA_FILE_TARGET = os.path.join(DATA_DIR, \"train_target.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['reason', '#earthquak', 'may', 'allah', 'us', 'forest', 'fire', 'near', 'la', 'canada']\n",
      "\n",
      "['Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all', 'Forest fire near La Ronge Sask. Canada', \"All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected\"]\n",
      "\n",
      "[['reason', '#earthquak', 'may', 'allah', 'us'], ['forest', 'fire', 'near', 'la', 'canada'], ['resid', 'ask', 'shelter', 'place', 'offic', 'evacu', 'shelter', 'place', 'order', 'expect']]\n"
     ]
    }
   ],
   "source": [
    "# USE LARGEST SET OF BAG OF WORDS (2944 TERMS)\n",
    "\n",
    "token_list = csv_to_list('data/tokens/train_text_token4.csv')\n",
    "print(token_list[0:10])\n",
    "print('')\n",
    "\n",
    "text_list = csv_to_list_of_strings(DATA_FILE_TEXT)\n",
    "print(text_list[0:3])\n",
    "print('')\n",
    "\n",
    "text_token_list = list_of_token_lists_text(text_list)\n",
    "print(text_token_list[0:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(7597, 2944)\n",
      "\n",
      "[['#1' '#360wisenew' '#7' ... '\\x89û÷polit' 'åè' 'åê']]\n",
      "(1, 2944)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "onehot_multi_text = MultiLabelBinarizer()\n",
    "\n",
    "onehot_text_nolabel = onehot_multi_text.fit_transform(text_token_list)\n",
    "num_row, num_col = onehot_text_nolabel.shape\n",
    "\n",
    "print(onehot_text_nolabel)\n",
    "print(onehot_text_nolabel.shape)\n",
    "print('')\n",
    "\n",
    "text_labels = onehot_multi_text.classes_\n",
    "text_labels = text_labels.reshape(1, num_col)\n",
    "\n",
    "print(text_labels)\n",
    "print(text_labels.shape)\n",
    "print(type(text_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['#1' '#360wisenew' '#7' ... '\\x89û÷polit' 'åè' 'åê']\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "onehot_text = np.concatenate((text_labels,onehot_text_nolabel), axis=0)\n",
    "print(onehot_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['earthquake', 'forestfire', 'evacuation', 'wildfires', 'wildfires', 'wildfires', 'flood', 'fire', 'evacuation', 'tornado']\n",
      "\n",
      "[['kw_earthquake'], ['kw_forestfire'], ['kw_evacuation'], ['kw_wildfires'], ['kw_wildfires'], ['kw_wildfires'], ['kw_flood'], ['kw_fire'], ['kw_evacuation'], ['kw_tornado']]\n"
     ]
    }
   ],
   "source": [
    "keyword_list = csv_to_list_of_strings(DATA_FILE_KEYWORD)\n",
    "print(keyword_list[0:10])\n",
    "print('')\n",
    "\n",
    "keyword_token_list = list_of_token_lists_keyword(keyword_list)\n",
    "print(keyword_token_list[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(7597, 227)\n",
      "\n",
      "[['kw_ablaze' 'kw_accident' 'kw_aftershock' 'kw_airplane_accident'\n",
      "  'kw_ambulance' 'kw_annihilated' 'kw_annihilation' 'kw_apocalypse'\n",
      "  'kw_armageddon' 'kw_army' 'kw_arson' 'kw_arsonist' 'kw_attack'\n",
      "  'kw_attacked' 'kw_avalanche' 'kw_battle' 'kw_bioterror'\n",
      "  'kw_bioterrorism' 'kw_blaze' 'kw_blazing' 'kw_bleeding' 'kw_blew_up'\n",
      "  'kw_blight' 'kw_blizzard' 'kw_blood' 'kw_bloody' 'kw_blown_up'\n",
      "  'kw_body_bag' 'kw_body_bagging' 'kw_body_bags' 'kw_bomb' 'kw_bombed'\n",
      "  'kw_bombing' 'kw_bridge_collapse' 'kw_buildings_burning'\n",
      "  'kw_buildings_on_fire' 'kw_burned' 'kw_burning' 'kw_burning_buildings'\n",
      "  'kw_bush_fires' 'kw_casualties' 'kw_casualty' 'kw_catastrophe'\n",
      "  'kw_catastrophic' 'kw_chemical_emergency' 'kw_cliff_fall' 'kw_collapse'\n",
      "  'kw_collapsed' 'kw_collide' 'kw_collided' 'kw_collision' 'kw_crash'\n",
      "  'kw_crashed' 'kw_crush' 'kw_crushed' 'kw_curfew' 'kw_cyclone'\n",
      "  'kw_damage' 'kw_danger' 'kw_dead' 'kw_death' 'kw_deaths' 'kw_debris'\n",
      "  'kw_deluge' 'kw_deluged' 'kw_demolish' 'kw_demolished' 'kw_demolition'\n",
      "  'kw_derail' 'kw_derailed' 'kw_derailment' 'kw_desolate' 'kw_desolation'\n",
      "  'kw_destroy' 'kw_destroyed' 'kw_destruction' 'kw_detonate'\n",
      "  'kw_detonation' 'kw_devastated' 'kw_devastation' 'kw_disaster'\n",
      "  'kw_displaced' 'kw_drought' 'kw_drown' 'kw_drowned' 'kw_drowning'\n",
      "  'kw_dust_storm' 'kw_earthquake' 'kw_electrocute' 'kw_electrocuted'\n",
      "  'kw_emergency' 'kw_emergency_plan' 'kw_emergency_services'\n",
      "  'kw_engulfed' 'kw_epicentre' 'kw_evacuate' 'kw_evacuated'\n",
      "  'kw_evacuation' 'kw_explode' 'kw_exploded' 'kw_explosion'\n",
      "  'kw_eyewitness' 'kw_famine' 'kw_fatal' 'kw_fatalities' 'kw_fatality'\n",
      "  'kw_fear' 'kw_fire' 'kw_fire_truck' 'kw_first_responders' 'kw_flames'\n",
      "  'kw_flattened' 'kw_flood' 'kw_flooding' 'kw_floods' 'kw_forest_fire'\n",
      "  'kw_forest_fires' 'kw_forestfire' 'kw_hail' 'kw_hailstorm' 'kw_harm'\n",
      "  'kw_hazard' 'kw_hazardous' 'kw_heat_wave' 'kw_heatwave' 'kw_hellfire'\n",
      "  'kw_hijack' 'kw_hijacker' 'kw_hijacking' 'kw_hostage' 'kw_hostages'\n",
      "  'kw_hurricane' 'kw_injured' 'kw_injuries' 'kw_injury' 'kw_inundated'\n",
      "  'kw_inundation' 'kw_landslide' 'kw_lava' 'kw_lightning' 'kw_loud_bang'\n",
      "  'kw_loudbang' 'kw_mass_murder' 'kw_mass_murderer' 'kw_massacre'\n",
      "  'kw_mayhem' 'kw_meltdown' 'kw_military' 'kw_mudslide'\n",
      "  'kw_natural_disaster' 'kw_nuclear_disaster' 'kw_nuclear_reactor'\n",
      "  'kw_obliterate' 'kw_obliterated' 'kw_obliteration' 'kw_oil_spill'\n",
      "  'kw_oilspill' 'kw_outbreak' 'kw_pandemonium' 'kw_panic' 'kw_panicking'\n",
      "  'kw_police' 'kw_quarantine' 'kw_quarantined' 'kw_radiation_emergency'\n",
      "  'kw_rainstorm' 'kw_razed' 'kw_refugees' 'kw_rescue' 'kw_rescued'\n",
      "  'kw_rescuers' 'kw_riot' 'kw_rioting' 'kw_rubble' 'kw_ruin'\n",
      "  'kw_sandstorm' 'kw_screamed' 'kw_screaming' 'kw_screams' 'kw_seismic'\n",
      "  'kw_sinkhole' 'kw_sinking' 'kw_siren' 'kw_sirens' 'kw_smoke'\n",
      "  'kw_snowstorm' 'kw_storm' 'kw_stretcher' 'kw_structural_failure'\n",
      "  'kw_suicide_bomb' 'kw_suicide_bomber' 'kw_suicide_bombing'\n",
      "  'kw_suicidebomber' 'kw_sunk' 'kw_survive' 'kw_survived' 'kw_survivors'\n",
      "  'kw_terrorism' 'kw_terrorist' 'kw_threat' 'kw_thunder'\n",
      "  'kw_thunderstorm' 'kw_tornado' 'kw_tragedy' 'kw_trapped' 'kw_trauma'\n",
      "  'kw_traumatised' 'kw_trouble' 'kw_tsunami' 'kw_twister' 'kw_typhoon'\n",
      "  'kw_upheaval' 'kw_violent_storm' 'kw_volcano' 'kw_war_zone' 'kw_weapon'\n",
      "  'kw_weapons' 'kw_whirlwind' 'kw_wild_fires' 'kw_wildfire'\n",
      "  'kw_wildfires' 'kw_windstorm' 'kw_wounded' 'kw_wounds' 'kw_wreck'\n",
      "  'kw_wreckage' 'kw_wrecked']]\n",
      "(1, 227)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "onehot_multi_keyword = MultiLabelBinarizer()\n",
    "onehot_keyword_nolabel = onehot_multi_keyword.fit_transform(keyword_token_list)\n",
    "num_row, num_col = onehot_keyword_nolabel.shape\n",
    "\n",
    "print(onehot_keyword_nolabel)\n",
    "print(onehot_keyword_nolabel.shape)\n",
    "print('')\n",
    "\n",
    "keyword_labels = onehot_multi_keyword.classes_\n",
    "keyword_labels = keyword_labels.reshape(1, num_col)\n",
    "\n",
    "print(keyword_labels)\n",
    "print(keyword_labels.shape)\n",
    "print(type(keyword_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['kw_ablaze' 'kw_accident' 'kw_aftershock' ... 'kw_wreck' 'kw_wreckage'\n",
      "  'kw_wrecked']\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "onehot_keyword = np.concatenate((keyword_labels,onehot_keyword_nolabel), axis=0)\n",
    "print(onehot_keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['kw_ablaze' 'kw_accident' 'kw_aftershock' ... '\\x89û÷polit' 'åè' 'åê']\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "onehot_train = np.concatenate((onehot_keyword,onehot_text), axis=1)\n",
    "print(onehot_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kw_ablaze</th>\n",
       "      <th>kw_accident</th>\n",
       "      <th>kw_aftershock</th>\n",
       "      <th>kw_airplane_accident</th>\n",
       "      <th>kw_ambulance</th>\n",
       "      <th>kw_annihilated</th>\n",
       "      <th>kw_annihilation</th>\n",
       "      <th>kw_apocalypse</th>\n",
       "      <th>kw_armageddon</th>\n",
       "      <th>kw_army</th>\n",
       "      <th>...</th>\n",
       "      <th>ûïa</th>\n",
       "      <th>ûïthe</th>\n",
       "      <th>ûïwe</th>\n",
       "      <th>ûïwhen</th>\n",
       "      <th>ûò</th>\n",
       "      <th>ûó</th>\n",
       "      <th>û÷extrem</th>\n",
       "      <th>û÷polit</th>\n",
       "      <th>åè</th>\n",
       "      <th>åê</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7592</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7593</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7594</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7595</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7596</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7597 rows × 3171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     kw_ablaze kw_accident kw_aftershock kw_airplane_accident kw_ambulance  \\\n",
       "0            0           0             0                    0            0   \n",
       "1            0           0             0                    0            0   \n",
       "2            0           0             0                    0            0   \n",
       "3            0           0             0                    0            0   \n",
       "4            0           0             0                    0            0   \n",
       "...        ...         ...           ...                  ...          ...   \n",
       "7592         0           0             0                    0            0   \n",
       "7593         0           0             0                    0            0   \n",
       "7594         0           0             0                    0            0   \n",
       "7595         0           0             0                    0            0   \n",
       "7596         0           0             0                    0            0   \n",
       "\n",
       "     kw_annihilated kw_annihilation kw_apocalypse kw_armageddon kw_army  ...  \\\n",
       "0                 0               0             0             0       0  ...   \n",
       "1                 0               0             0             0       0  ...   \n",
       "2                 0               0             0             0       0  ...   \n",
       "3                 0               0             0             0       0  ...   \n",
       "4                 0               0             0             0       0  ...   \n",
       "...             ...             ...           ...           ...     ...  ...   \n",
       "7592              0               0             0             0       0  ...   \n",
       "7593              0               0             0             0       0  ...   \n",
       "7594              0               0             0             0       0  ...   \n",
       "7595              0               0             0             0       0  ...   \n",
       "7596              0               0             0             0       0  ...   \n",
       "\n",
       "     ûïa ûïthe ûïwe ûïwhen ûò ûó û÷extrem û÷polit åè åê  \n",
       "0       0      0     0       0   0   0         0        0  0  0  \n",
       "1       0      0     0       0   0   0         0        0  0  0  \n",
       "2       0      0     0       0   0   0         0        0  0  0  \n",
       "3       0      0     0       0   0   0         0        0  0  0  \n",
       "4       0      0     0       0   0   0         0        0  0  0  \n",
       "...   ...    ...   ...     ...  ..  ..       ...      ... .. ..  \n",
       "7592    0      0     0       0   0   0         0        0  0  0  \n",
       "7593    0      0     0       0   0   0         0        0  0  0  \n",
       "7594    0      0     0       0   0   0         0        0  0  0  \n",
       "7595    0      0     0       0   0   0         0        0  0  0  \n",
       "7596    0      0     0       0   0   0         0        0  0  0  \n",
       "\n",
       "[7597 rows x 3171 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.DataFrame(data=onehot_train[1:], columns=onehot_train[0,0:])\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **APPEND TARGET COLUMN TO TRAINING SET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7592</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7593</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7594</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7595</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7596</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7597 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      target\n",
       "0          1\n",
       "1          1\n",
       "2          1\n",
       "3          1\n",
       "4          1\n",
       "...      ...\n",
       "7592       1\n",
       "7593       1\n",
       "7594       1\n",
       "7595       1\n",
       "7596       1\n",
       "\n",
       "[7597 rows x 1 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target = csv_to_dataframe(DATA_FILE_TARGET)\n",
    "train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kw_ablaze</th>\n",
       "      <th>kw_accident</th>\n",
       "      <th>kw_aftershock</th>\n",
       "      <th>kw_airplane_accident</th>\n",
       "      <th>kw_ambulance</th>\n",
       "      <th>kw_annihilated</th>\n",
       "      <th>kw_annihilation</th>\n",
       "      <th>kw_apocalypse</th>\n",
       "      <th>kw_armageddon</th>\n",
       "      <th>kw_army</th>\n",
       "      <th>...</th>\n",
       "      <th>ûïthe</th>\n",
       "      <th>ûïwe</th>\n",
       "      <th>ûïwhen</th>\n",
       "      <th>ûò</th>\n",
       "      <th>ûó</th>\n",
       "      <th>û÷extrem</th>\n",
       "      <th>û÷polit</th>\n",
       "      <th>åè</th>\n",
       "      <th>åê</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7592</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7593</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7594</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7595</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7596</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7597 rows × 3172 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     kw_ablaze kw_accident kw_aftershock kw_airplane_accident kw_ambulance  \\\n",
       "0            0           0             0                    0            0   \n",
       "1            0           0             0                    0            0   \n",
       "2            0           0             0                    0            0   \n",
       "3            0           0             0                    0            0   \n",
       "4            0           0             0                    0            0   \n",
       "...        ...         ...           ...                  ...          ...   \n",
       "7592         0           0             0                    0            0   \n",
       "7593         0           0             0                    0            0   \n",
       "7594         0           0             0                    0            0   \n",
       "7595         0           0             0                    0            0   \n",
       "7596         0           0             0                    0            0   \n",
       "\n",
       "     kw_annihilated kw_annihilation kw_apocalypse kw_armageddon kw_army  ...  \\\n",
       "0                 0               0             0             0       0  ...   \n",
       "1                 0               0             0             0       0  ...   \n",
       "2                 0               0             0             0       0  ...   \n",
       "3                 0               0             0             0       0  ...   \n",
       "4                 0               0             0             0       0  ...   \n",
       "...             ...             ...           ...           ...     ...  ...   \n",
       "7592              0               0             0             0       0  ...   \n",
       "7593              0               0             0             0       0  ...   \n",
       "7594              0               0             0             0       0  ...   \n",
       "7595              0               0             0             0       0  ...   \n",
       "7596              0               0             0             0       0  ...   \n",
       "\n",
       "     ûïthe ûïwe ûïwhen ûò ûó û÷extrem û÷polit åè åê target  \n",
       "0         0     0       0   0   0         0        0  0  0      1  \n",
       "1         0     0       0   0   0         0        0  0  0      1  \n",
       "2         0     0       0   0   0         0        0  0  0      1  \n",
       "3         0     0       0   0   0         0        0  0  0      1  \n",
       "4         0     0       0   0   0         0        0  0  0      1  \n",
       "...     ...   ...     ...  ..  ..       ...      ... .. ..    ...  \n",
       "7592      0     0       0   0   0         0        0  0  0      1  \n",
       "7593      0     0       0   0   0         0        0  0  0      1  \n",
       "7594      0     0       0   0   0         0        0  0  0      1  \n",
       "7595      0     0       0   0   0         0        0  0  0      1  \n",
       "7596      0     0       0   0   0         0        0  0  0      1  \n",
       "\n",
       "[7597 rows x 3172 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_with_target = pd.concat([train_df, train_target], axis=1)\n",
    "train_df_with_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **CONVERT DATAFRAME TO CSV FILE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE_BOW = os.path.join(DATA_DIR, \"bow/train_bow.csv\")\n",
    "\n",
    "dataframe_to_csv(train_df_with_target, DATA_FILE_BOW)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
